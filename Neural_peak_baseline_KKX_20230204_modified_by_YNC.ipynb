{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.signal import savgol_filter\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import peakutils\n",
    "\n",
    "def distance(data): # generate distance matrix\n",
    "    b = pdist(data)\n",
    "    pattern = squareform(b)\n",
    "    d = pd.DataFrame(pattern)\n",
    "    return d\n",
    "\n",
    "def moving_average(x, w):                          #'w' is the smoothing level,'x' is the data required to be smoothed\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'output' already exists.\n",
      "20221016YR_triple_7%tBuOOH_calcium_signal\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "20211205YR_OH16230_5%tBOOH_calcium_signal\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('output') # create file named \"output\"\n",
    "except:\n",
    "    print('Directory \\'output\\' already exists.')\n",
    "\n",
    "for file_name in glob.glob('*signal.xlsx'):\n",
    "    base_name = Path(file_name).stem\n",
    "    print(base_name)\n",
    "    df = pd.read_excel(file_name, sheet_name=0)\n",
    "    nNeuron = len(df.iloc[0,:])-4       # number of neurons\n",
    "    for i in range(0,nNeuron-1):\n",
    "        if pd.isna(df.iloc[i,1]) == True:\n",
    "            df.iloc[i,1] = 'n'+str(i+1)\n",
    "        elif str(df.iloc[i,1]).isspace() == True:\n",
    "            df.iloc[i,1] = 'n'+str(i+1)\n",
    "    nameList = df.iloc[0:nNeuron,1].tolist()\n",
    "    df_nameList = pd.DataFrame(nameList).T\n",
    "    writer = pd.ExcelWriter(f'output/{base_name}_near_smooth_distan_corre_deri.xlsx', engine=\"xlsxwriter\")\n",
    "    # df = pd.read_excel('File18_20210701YR_OH16230_death-10sInt.xlsx')\n",
    "    \"\"\"\n",
    "    get distance\n",
    "    \"\"\"\n",
    "    df1=df.iloc[:,0:3]\n",
    "    df1.dropna(thresh = 2, inplace = True)        \n",
    "    xy = []\n",
    "    for i in df1.iloc[:,2]:\n",
    "        xy.append(re.findall('\\d+',i))\n",
    "    xy = np.array(xy)\n",
    "    xyP =np.delete(xy, np.s_[:1:1], 1)\n",
    "    dis = distance(float64(xyP))                 # get distance between each two neurons\n",
    "\n",
    "    \"\"\"\n",
    "    smooth\n",
    "    \"\"\"\n",
    "    df2 = df.iloc[:,4:]\n",
    "    data = []\n",
    "    for i in df2.keys()[0:]:\n",
    "        data.append(savgol_filter(df2[i], 71, 10))    \n",
    "    dff = pd.DataFrame(data).T\n",
    "    dff.to_excel(writer, sheet_name='smoo_savgol', header=nameList)\n",
    "\n",
    "    \"\"\"\n",
    "    moving average\n",
    "    \"\"\"\n",
    "    smooth=pd.DataFrame(list(dff.index))\n",
    "    # smooth=pd.DataFrame(moving_average(df.iloc[:,1],2),columns=['S1'])\n",
    "    for i in dff.keys()[0:]:\n",
    "        smooth[i]=pd.DataFrame(moving_average(dff[i],15))\n",
    "    smooth = smooth.dropna()\n",
    "    smooth1 = smooth.dropna()\n",
    "    smooth.to_excel(writer, sheet_name='smoo_aver', header=nameList)\n",
    "\n",
    "    #smooth2 = dff.rolling(5, center=True, min_periods=1).mean()\n",
    "    #smooth2.to_excel('smoothed.xlsx', index=False, header=None)\n",
    "\n",
    "    \"\"\"\n",
    "    get correlations\n",
    "    \"\"\"\n",
    "    correlations = dff.corr()\n",
    "\n",
    "    dis.to_excel(writer, sheet_name='distance', header=nameList)\n",
    "    correlations.to_excel(writer, sheet_name='correlation', header=nameList)\n",
    "\n",
    "    \"\"\"\n",
    "    get data point for each neuron pair### (x,y), x = distance between one pair of neuron; \n",
    "    y = correlation between one pair of neuron\n",
    "    \"\"\"\n",
    "    dist = []\n",
    "    for i in dis.keys():\n",
    "        if i == 97:\n",
    "            break\n",
    "        dist = dist + list(dis.iloc[i+1:,i])\n",
    "\n",
    "    correl = []\n",
    "    for i in correlations.keys():\n",
    "        if i == 97:\n",
    "            break\n",
    "        correl = correl + list(correlations.iloc[i+1:,i])\n",
    "\n",
    "    spss = pd.DataFrame([dist,correl]).T\n",
    "    spss.to_excel(writer, sheet_name='dis_corr_datapair',index=False)\n",
    "\n",
    "    \"\"\"\n",
    "    derivative\n",
    "    \"\"\"\n",
    "    derivative = pd.DataFrame(smooth.rolling(window=2).apply(lambda x: x.iloc[1] - x.iloc[0]))/0.133333\n",
    "\n",
    "    derivative.to_excel(writer, sheet_name='deri',index=False, header=nameList) \n",
    "    \n",
    "    \n",
    "    writer1 = pd.ExcelWriter(f'output/{base_name}_near_peak_baseline.xlsx', engine=\"xlsxwriter\")\n",
    "    \"\"\"\n",
    "    get peak value and index\n",
    "    \"\"\" \n",
    "    peak_p = []\n",
    "    peak_s = []\n",
    "    base = []\n",
    "    bb = 0\n",
    "    for i in smooth.keys():\n",
    "        data1 = smooth.iloc[20:,i]\n",
    "        \n",
    "        x_peak = data1.idxmax()      \n",
    "        y_peak = data1.max()\n",
    "        peak_p.append([x_peak,y_peak])\n",
    "        \"\"\"\n",
    "        get baseline\n",
    "        \"\"\"\n",
    "        baseline_values = peakutils.baseline(smooth.iloc[:,i])\n",
    "        baseline = np.average(baseline_values)\n",
    "        base.append(baseline_values)\n",
    "\n",
    "        \"\"\"\n",
    "        get start of peak\n",
    "        \"\"\"    \n",
    "        p_data = smooth.iloc[: x_peak + 1, i][::-1] #[::-1] can reverse the order of row & p_data.iloc[:, ::-1] or p_data.columns[::-1] reverses the order of the DataFrame's sequence of columns\n",
    "        for m in p_data.keys():\n",
    "        #     print(p_data[i])\n",
    "            standard = baseline_values[m]\n",
    "            if p_data[m] < standard:\n",
    "                x_s = m\n",
    "                y_s = p_data[m]\n",
    "                peak_s.append([x_s,y_s])\n",
    "                break\n",
    "            elif m == 0:\n",
    "                peak_s.append([0,0])\n",
    "                print(0)\n",
    "            else:\n",
    "                continue\n",
    "    #     print(x_l,y_l)    \n",
    "\n",
    "    base =  pd.DataFrame(base).T\n",
    "    peak_p = pd.DataFrame(peak_p)\n",
    "    peak_s = pd.DataFrame(peak_s)\n",
    "    base.to_excel(writer, sheet_name='baseline', header=nameList) \n",
    "    \"\"\"\n",
    "    get true baseline\n",
    "    \"\"\"\n",
    "    baseline_l = []\n",
    "    for i in smooth.keys():\n",
    "        l_dex = int(peak_s.iloc[i,0])\n",
    "        if l_dex == 0:\n",
    "            baseline_values = peakutils.baseline(smooth.iloc[:,i])\n",
    "            baseline = np.average(baseline_values)\n",
    "        else:\n",
    "            new_d = smooth.iloc[:l_dex,i]\n",
    "            baseline_values = peakutils.baseline(new_d)\n",
    "            baseline = np.average(baseline_values)\n",
    "        baseline_l.append(baseline)    \n",
    "        smooth1.iloc[:,i] = (smooth1.iloc[:,i] - baseline)/baseline\n",
    "    baseline_l = pd.DataFrame(baseline_l)\n",
    "    baseline_l.to_excel(writer, sheet_name='baseline_value') \n",
    "    smooth1.to_excel(writer, sheet_name='F0_Normoli', header=nameList) \n",
    "    writer.close()\n",
    "    ######################################\n",
    "    #####after this, should amplitude = peak value\n",
    "    ######################################\n",
    "    \"\"\"\n",
    "    get true peak\n",
    "    \"\"\"\n",
    "    peak_p2 = []\n",
    "    peak_s2 = []\n",
    "    amplit = []\n",
    "    for i in smooth1.keys():\n",
    "        data2 = smooth1.iloc[20:,i]\n",
    "        x_peak2 = data2.idxmax()\n",
    "        y_peak2 = data2.max()\n",
    "        peak_p2.append([x_peak2,y_peak2])\n",
    "        \n",
    "    peak_p2 = pd.DataFrame(peak_p2,columns = ['x_peak','y_peak'])\n",
    "    \"\"\"\n",
    "    start of peak after normalisation\n",
    "    \"\"\"\n",
    "    peak_s2 = []\n",
    "    for i in smooth1.keys():\n",
    "        x_l2 = peak_s.iloc[i,0]\n",
    "        y_l2 = smooth1.iloc[x_l2,i]\n",
    "        peak_s2.append([x_l2,y_l2])\n",
    "    peak_s2 = pd.DataFrame(peak_s2,columns = ['x_start','y_start'])\n",
    "\n",
    "    x_dis = peak_p2['x_peak']-peak_s2['x_start']\n",
    "    y_dis = peak_p2['y_peak']-peak_s2['y_start']\n",
    "    xy_ratio = y_dis/x_dis\n",
    "    xy_dis = pd.DataFrame([x_dis,y_dis,xy_ratio],index = ['x_distance',\"y_distance\",\"xy_ratio\"]).T\n",
    "    \n",
    "    peak2 = pd.concat([peak_s2,peak_p2,xy_dis], axis = 1)\n",
    "    peak2.to_excel(writer1, sheet_name='peak') \n",
    "    writer1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test if the index of statr is 0 or 20\n",
    "\"\"\"\n",
    "qq = 0\n",
    "for i in peak_s[0]:\n",
    "    if i == 0 or i == 20:\n",
    "        print(qq)\n",
    "    qq += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
